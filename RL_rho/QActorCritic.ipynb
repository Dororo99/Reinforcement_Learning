{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMXj45pN0M5RYlNSWCx07c1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"Otge7zPf4CDW","executionInfo":{"status":"error","timestamp":1743234587010,"user_tz":-540,"elapsed":17264,"user":{"displayName":"T0gether","userId":"02236468154512718371"}},"outputId":"d60e81f4-1ee7-4939-e41a-972958938a2a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]},{"output_type":"error","ename":"ValueError","evalue":"too many values to unpack (expected 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-244671c9472f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-1-244671c9472f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn_epi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}],"source":["import gym\n","import collections\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.distributions import Categorical\n","\n","# Set Hyperparameters\n","LR = 1e-3\n","GAMMA = 0.98\n","\n","# Set Model\n","class QActorCritic(nn.Module):\n","    def __init__(self):\n","        super(QActorCritic,self).__init__()\n","        self.data = []\n","\n","        self.fc1 = nn.Linear(4,256)\n","        self.fc_pi = nn.Linear(256,2)\n","        self.fc_v = nn.Linear(256,1)\n","        self.optimizer = optim.Adam(self.parameters(),lr=LR)\n","\n","    def pi(self, x, softmax_dim=0):\n","        x = F.relu(self.fc1(x))\n","        x = self.fc_pi(x)\n","        prob = F.softmax(x, dim=softmax_dim)\n","        return prob\n","\n","    def v(self, x):\n","        x = F.relu(self.fc1(x))\n","        v = self.fc_v(x)\n","        return v\n","\n","    def put_data(self, transition):\n","        self.data.append(transition)\n","\n","    def make_batch(self):\n","        s_lst,a_lst,r_lst,s_prime_lst,done_lst = [],[],[],[],[]\n","        for transition in self.data:\n","            s,a,r,s_prime,done = transition\n","            s_lst.append(s)\n","            a_lst.append([a])\n","            r_lst.append([r/100.0])\n","            s_prime_lst.append(s_prime)\n","            done_mask = 0.0 if done else 1.0\n","            done_lst.append([done_mask])\n","\n","        s_batch, a_batch, r_batch, s_prime_batch, done_batch = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst),torch.tensor(r_lst,dtype=torch.float),torch.tensor(s_prime_lst, dtype =torch.float),torch.tensor(done_lst,dtype=torch.float)\n","\n","        self.data = []\n","        return s_batch,a_batch,r_batch,s_prime_batch,done_batch\n","\n","    def train_net(self):\n","        s,a,r,s_prime,done = self.make_batch()\n","        v_prime = self.v(s_prime) * done\n","        pi = self.pi(s,softmax_dim=1)\n","        pi_a = pi.gather(1,a)\n","        pi_loss = -torch.log(pi_a)*self.v(s).detach()\n","        td_target = r + GAMMA*v_prime\n","        v_loss = F.smooth_l1_loss(self.v(s),td_target.detach())\n","\n","        loss = pi_loss + v_loss\n","\n","        self.optimizer.zero_grad()\n","        loss.mean().backward()\n","        self.optimizer.step()\n","\n","def main():\n","    env = gym.make('CartPole-v1')\n","    model = QActorCritic()\n","    print_interval = 20\n","    score = 0.0\n","\n","    for n_epi in range(10000):\n","        done = False\n","        s, _ = env.reset()\n","\n","        while not done:\n","            prob = model.pi(torch.from_numpy(s).float())\n","            m = Categorical(prob)\n","            a = m.sample().item()\n","            s_prime, r, done, truncated, info = env.step(a)\n","            model.put_data((s,a,r,s_prime,done))\n","\n","            s = s_prime\n","            score += r\n","\n","            if done:\n","                break\n","            model.train_net()\n","        if n_epi%print_interval==0 and n_epi!=0:\n","            print(\"[EPISODE]: {}, [avg score]: {:.1f}\".format(n_epi, score/print_interval))\n","            score = 0.0\n","    env.close()\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}