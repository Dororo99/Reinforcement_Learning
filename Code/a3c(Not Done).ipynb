{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNKbRgT9S5OsoGkGBtbuCgl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# %pip uninstall numpy -Y\n","# %pip install numpy==1.23.5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":655},"id":"4O0u-7pHIOdH","executionInfo":{"status":"ok","timestamp":1743305617321,"user_tz":-540,"elapsed":8560,"user":{"displayName":"T0gether","userId":"02236468154512718371"}},"outputId":"c3e4b312-8fa0-4c0a-80ba-eed9d90466dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Usage:   \n","  pip3 uninstall [options] <package> ...\n","  pip3 uninstall [options] -r <requirements file> ...\n","\n","no such option: -Y\n","Collecting numpy==1.23.5\n","  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n","Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n","albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","blosc2 3.2.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n","chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n","jax 0.5.2 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n","bigframes 1.41.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n","imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n","xarray 2025.1.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n","scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.23.5 which is incompatible.\n","pymc 5.21.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"879591c6e67a48518f5df40f3c4ce590"}},"metadata":{}}]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7EbGQ7sxCbe2","executionInfo":{"status":"ok","timestamp":1743657918458,"user_tz":-540,"elapsed":18,"user":{"displayName":"T0gether","userId":"02236468154512718371"}}},"outputs":[],"source":["import gym\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.distributions import Categorical\n","import torch.multiprocessing as mp\n","import time\n","import numpy as np"]},{"cell_type":"code","source":["# Set Hyperparmeters\n","n_train_processes = 3\n","LR = 0.0002\n","update_intervals = 5\n","GAMMA = 0.98\n","max_train_ep = 300\n","max_test_ep = 400"],"metadata":{"id":"JeUwP0HFCkw4","executionInfo":{"status":"ok","timestamp":1743657919453,"user_tz":-540,"elapsed":4,"user":{"displayName":"T0gether","userId":"02236468154512718371"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class ActorCritic(nn.Module):\n","  def __init__(self):\n","    super(ActorCritic,self).__init__()\n","    self.fc1 = nn.Linear(4,256)\n","    self.fc_pi = nn.Linear(256,2)\n","    self.fc_v = nn.Linear(256,1)\n","\n","  def pi(self,x,softmax_dim=0):\n","    x = F.relu(self.fc1(x))\n","    prob = F.softmax(self.fc_pi(x), dim=softmax_dim)\n","    return prob\n","\n","  def v(self, x):\n","    x = F.relu(self.fc1(x))\n","    v = self.fc_v(x)\n","    return v"],"metadata":{"id":"kZgTiu8wC0ni","executionInfo":{"status":"ok","timestamp":1743657920838,"user_tz":-540,"elapsed":9,"user":{"displayName":"T0gether","userId":"02236468154512718371"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Train\n","lock = mp.Lock()\n","def train(global_model, rank):\n","  local_model = ActorCritic()\n","  local_model.load_state_dict(global_model.state_dict())\n","\n","  optimizer = optim.Adam(global_model.parameters(),lr=LR)\n","\n","  env = gym.make('CartPole-v1', new_step_api=True)\n","\n","  for n_epi in range(max_train_ep):\n","    done = False\n","    s = env.reset()\n","\n","    while not done:\n","      s_lst, a_lst, r_lst = [],[],[]\n","      for i in range(update_intervals):\n","        prob = local_model.pi(torch.from_numpy(s).float())\n","        m = Categorical(prob)\n","        a = m.sample().item()\n","        s_prime,r,done,info, _ = env.step(a)\n","\n","        s_lst.append(s)\n","        a_lst.append([a])\n","        r_lst.append(r/100.0)\n","\n","        s = s_prime\n","        if done:\n","          break\n","\n","      s_final = torch.tensor(np.array(s_prime), dtype=torch.float)\n","      R = 0.0 if done else local_model.v(s_final).item()\n","      td_target_lst = []\n","\n","      # Get Advantage (using Returns G_t)\n","      for reward in r_lst[::-1]:\n","        R = reward + GAMMA * R\n","        td_target_lst.append([R])\n","      td_target_lst.reverse()\n","\n","      # s_batch,a_batch,td_target = torch.tensor(np.array(s_lst), dtype=torch.float), torch.tensor(a_lst), torch.tensor(td_target_lst)\n","      s_batch,a_batch,td_target = torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), torch.tensor(td_target_lst)\n","\n","      advantage = td_target - local_model.v(s_batch)\n","\n","      pi = local_model.pi(s_batch, softmax_dim=1)\n","      pi_a = pi.gather(1,a_batch)\n","      loss = -torch.log(pi_a)*advantage.detach() + F.smooth_l1_loss(local_model.v(s_batch), td_target.detach())\n","\n","      optimizer.zero_grad()\n","      loss.mean().backward()\n","      for global_param, local_param in zip(global_model.parameters(),local_model.parameters()):\n","        # global_param.grad = local_param.grad.clone()\n","        global_param._grad = local_param.grad\n","      optimizer.step()\n","      local_model.load_state_dict(global_model.state_dict())\n","\n","  env.close()\n","  print(\"Traning_Process {} reached maximum episode.\".format(rank))"],"metadata":{"id":"-_6d4O0wDeKT","executionInfo":{"status":"ok","timestamp":1743657922254,"user_tz":-540,"elapsed":4,"user":{"displayName":"T0gether","userId":"02236468154512718371"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def test(global_model):\n","  env = gym.make(\"CartPole-v1\")\n","  score = 0.0\n","  print_interval = 20\n","\n","  for n_epi in range(max_test_ep):\n","    done = False\n","    s = env.reset()\n","\n","    while not done:\n","      prob = global_model.pi(torch.from_numpy(s).float())\n","      a = Categorical(prob).sample().item()\n","      s_prime, r, done,_ = env.step(a)\n","      s = s_prime\n","      score += r\n","\n","    if n_epi % print_interval == 0 and n_epi != 0:\n","      print(f\"[Episode]: {n_epi} [Avg Score]: {(score/print_interval):.2f}\")\n","      score = 0.0\n","      time.sleep(1)\n","\n","  env.close()"],"metadata":{"id":"B46_SjGRGx28","executionInfo":{"status":"ok","timestamp":1743657924410,"user_tz":-540,"elapsed":3,"user":{"displayName":"T0gether","userId":"02236468154512718371"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","  global_model = ActorCritic()\n","  global_model.share_memory()\n","\n","  processes = []\n","  for rank in range(n_train_processes + 1):\n","    if rank == 0:\n","      p = mp.Process(target = test, args=(global_model,))\n","    else:\n","      p = mp.Process(target = train, args=(global_model,rank,))\n","\n","    p.start()\n","    processes.append(p)\n","\n","  for p in processes:\n","    p.join()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7rMXlENHe6Q","executionInfo":{"status":"ok","timestamp":1743657932207,"user_tz":-540,"elapsed":4676,"user":{"displayName":"T0gether","userId":"02236468154512718371"}},"outputId":"d247c7ef-eab6-4d34-ea3a-24346d80d31c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","Process Process-5:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"<ipython-input-11-9549c789071b>\", line 13, in test\n","    s_prime, r, done,_ = env.step(a)\n","                         ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/time_limit.py\", line 60, in step\n","    self.env.step(action),\n","    ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\", line 37, in step\n","    return self.env.step(action)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py\", line 52, in step\n","    step_returns = self.env.step(action)\n","                   ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\", line 37, in step\n","    return env_step_passive_checker(self.env, action)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py\", line 241, in env_step_passive_checker\n","    if not isinstance(terminated, (bool, np.bool8)):\n","                                         ^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 410, in __getattr__\n","    raise AttributeError(\"module {!r} has no attribute \"\n","AttributeError: module 'numpy' has no attribute 'bool8'\n","Process Process-6:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"<ipython-input-10-3ad545b88b57>\", line 21, in train\n","    s_prime,r,done,info, _ = env.step(a)\n","                             ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/time_limit.py\", line 60, in step\n","    self.env.step(action),\n","    ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\", line 37, in step\n","    return self.env.step(action)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py\", line 52, in step\n","    step_returns = self.env.step(action)\n","                   ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\", line 37, in step\n","    return env_step_passive_checker(self.env, action)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py\", line 241, in env_step_passive_checker\n","    if not isinstance(terminated, (bool, np.bool8)):\n","                                         ^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 410, in __getattr__\n","    raise AttributeError(\"module {!r} has no attribute \"\n","AttributeError: module 'numpy' has no attribute 'bool8'\n","Process Process-7:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"<ipython-input-10-3ad545b88b57>\", line 21, in train\n","    s_prime,r,done,info, _ = env.step(a)\n","                             ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/time_limit.py\", line 60, in step\n","    self.env.step(action),\n","    ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\", line 37, in step\n","    return self.env.step(action)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py\", line 52, in step\n","    step_returns = self.env.step(action)\n","                   ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\", line 37, in step\n","    return env_step_passive_checker(self.env, action)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py\", line 241, in env_step_passive_checker\n","    if not isinstance(terminated, (bool, np.bool8)):\n","                                         ^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 410, in __getattr__\n","    raise AttributeError(\"module {!r} has no attribute \"\n","AttributeError: module 'numpy' has no attribute 'bool8'\n","Process Process-8:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"<ipython-input-10-3ad545b88b57>\", line 21, in train\n","    s_prime,r,done,info, _ = env.step(a)\n","                             ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/time_limit.py\", line 60, in step\n","    self.env.step(action),\n","    ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/order_enforcing.py\", line 37, in step\n","    return self.env.step(action)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py\", line 52, in step\n","    step_returns = self.env.step(action)\n","                   ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/wrappers/env_checker.py\", line 37, in step\n","    return env_step_passive_checker(self.env, action)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py\", line 241, in env_step_passive_checker\n","    if not isinstance(terminated, (bool, np.bool8)):\n","                                         ^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\", line 410, in __getattr__\n","    raise AttributeError(\"module {!r} has no attribute \"\n","AttributeError: module 'numpy' has no attribute 'bool8'\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"6VtUPbNBS8Kt"},"execution_count":null,"outputs":[]}]}